{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/calc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's first understand how backpropagation works\n",
    "\n",
    "![alt text](https://i.ytimg.com/vi/An5z8lR8asY/maxresdefault.jpg \"Logo Title Text 1\")\n",
    "\n",
    "In 1986 Hinton released [this](http://www.cs.toronto.edu/~hinton/absps/naturebp.pdf) paper detailing a new optimization strategy for neural networks called 'backpropagation'. This paper is the reason the current Deep Learning boom is possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 concepts behind Backpropagtion (From Calculus)\n",
    "\n",
    "1. Derivative\n",
    "![alt text](https://i.imgur.com/eRF9pXu.jpg \"Logo Title Text 1\")\n",
    "\n",
    "2. Partial Derivative\n",
    "\n",
    "![alt text](https://i.imgur.com/Rergqbt.jpg \"Logo Title Text 1\")\n",
    "\n",
    "3. Chain Rule\n",
    "\n",
    "![alt text](https://i.imgur.com/HFmGQyH.jpg \"Logo Title Text 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/bp1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/bp2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l1 = 0.05\n",
    "# l2 = 0.10\n",
    "# o1 = 0.90\n",
    "# o2 = 0.78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A single Neuron\n",
    "inputs = [1.2,5.6,2.1]\n",
    "weights = [3.1,2.1,9.8]\n",
    "bias = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = inputs[0]*weights[0] + inputs[1]*weights[1] + inputs[2]*weights[2] + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.06"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A single Layer\n",
    "inputs = [1.2,5.6,2.1,2.5]\n",
    "weights1 = [3.1,2.1,9.8,1.0]\n",
    "weights2 = [5.1,6.1,4.8,7.0]\n",
    "weights3 = [6.1,4.1,5.8,6.0]\n",
    "bias1 = 1.0\n",
    "bias2 = 2.0\n",
    "bias3 = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = [inputs[0]*weights1[0] + inputs[1]*weights1[1] + inputs[2]*weights1[2] + inputs[3]* weights1[3] + bias1,\n",
    "         inputs[0]*weights2[0] + inputs[1]*weights2[1] + inputs[2]*weights2[2] + inputs[3]* weights2[3] + bias2,\n",
    "         inputs[0]*weights3[0] + inputs[1]*weights3[1] + inputs[2]*weights3[2] + inputs[3]* weights3[3] + bias3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[39.56, 69.85999999999999, 57.959999999999994]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [1.2,5.6,2.1,2.5]\n",
    "weights = [[3.1,2.1,9.8,1.0],\n",
    "          [5.1,6.1,4.8,7.0],\n",
    "          [6.1,4.1,5.8,6.0]]\n",
    "\n",
    "bias = [1.0,2.0,0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = np.dot(weights,inputs) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bias_and_weights(inputs,neurons):\n",
    "    weights = 0.10*(np.random.randn(inputs,neurons))\n",
    "    biases = np.zeros((1,neurons))\n",
    "    print(weights)\n",
    "    print(biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.23369231e-02  1.48732726e-01 -1.47231522e-01 -2.45400033e-02\n",
      "  -5.82388308e-02  7.37313447e-02 -1.36764884e-01 -1.99994852e-02\n",
      "  -3.45012562e-02  3.27411311e-02 -1.24379263e-02  9.95091459e-02\n",
      "   5.84661652e-02 -3.19422668e-02  3.55581915e-02 -1.69456914e-02\n",
      "  -1.01487495e-01 -1.18388353e-01 -3.52350005e-02 -9.29561613e-02\n",
      "   1.95958603e-01  1.84947977e-01  1.61249874e-02  4.16377566e-04\n",
      "   1.32785295e-01 -9.45944896e-02 -1.55866338e-01 -7.92354078e-02\n",
      "   1.06658675e-01  1.47139948e-01  1.73918711e-01 -6.21492092e-02\n",
      "  -4.59484971e-02  4.74428580e-02 -5.94946271e-02 -1.14002993e-02\n",
      "   7.01280888e-02 -1.27643691e-01  7.09636066e-02 -1.49851904e-01\n",
      "   9.32289675e-02  7.12097224e-03 -3.86660259e-02 -3.16910754e-01\n",
      "  -1.89150075e-01  1.40418232e-01 -1.98262137e-01  2.41051226e-02\n",
      "   1.30451792e-01 -3.91056360e-04  4.54836167e-02 -1.06557206e-01\n",
      "  -2.21001900e-02  4.31564359e-02 -1.31428512e-02  3.97618589e-02\n",
      "  -1.46842770e-01 -6.08110734e-03  7.07789081e-02 -1.70350731e-01\n",
      "   7.89855451e-02 -1.17060256e-01 -1.27082200e-01 -2.76278825e-02\n",
      "  -4.97595606e-02 -5.60983466e-02  1.95393544e-01  8.37395155e-02\n",
      "  -1.06879528e-01  7.94229114e-02  1.18989752e-01  1.13004805e-01\n",
      "  -4.86574120e-03  6.10083396e-02  5.29691734e-02 -4.01277596e-02\n",
      "   5.18163688e-02 -1.47598828e-01 -8.03602916e-02 -2.93761087e-02\n",
      "  -2.93291076e-02 -2.18892772e-01 -2.13738934e-04  9.32405079e-02\n",
      "  -6.55455665e-02  1.37474813e-01  3.64999896e-03 -7.32063728e-02\n",
      "  -5.73496353e-02  1.25237019e-01  1.15735417e-01  6.25178581e-02\n",
      "  -1.24048781e-02  5.50284826e-02  5.86467202e-02 -4.47796615e-02\n",
      "  -4.72155328e-02 -5.75388632e-02 -2.43733165e-01  6.92743203e-02\n",
      "   3.46552031e-02 -1.01424195e-01  3.04373249e-03 -1.97607162e-02\n",
      "   7.78300030e-02 -7.03160095e-02  2.31652884e-02 -1.40303459e-01\n",
      "   1.44444831e-02  2.65486366e-02  1.07118160e-01 -1.36595176e-01\n",
      "  -6.33615238e-03  8.25944679e-02 -1.93222278e-02  2.44949973e-02\n",
      "  -6.45516045e-02 -1.25185760e-01  1.83126745e-02 -7.46460747e-02\n",
      "   1.27905451e-01  8.97721579e-02 -6.93347607e-02 -4.35314495e-02\n",
      "  -2.72786717e-02  1.13221386e-02  1.17226382e-01 -7.24870082e-02]\n",
      " [-1.99055801e-01 -1.31236247e-01 -9.96672988e-02  7.02675122e-02\n",
      "  -5.22565312e-02  7.96042042e-02 -1.00235794e-01 -5.52267755e-02\n",
      "  -7.64288793e-03 -6.25483368e-02  1.55849498e-01  4.23242251e-02\n",
      "  -2.69684328e-01  1.96941510e-01 -5.47698814e-02  2.01076619e-02\n",
      "   2.57371055e-02  3.96742955e-02  9.82183823e-02 -6.20024582e-02\n",
      "   6.12128764e-02 -5.94427323e-02  6.74298843e-03 -1.30826692e-01\n",
      "  -1.98541969e-01  7.59581804e-02  5.74119090e-02  1.33203384e-01\n",
      "   2.60490392e-02  7.39624080e-03 -2.17272954e-01  1.46973029e-01\n",
      "  -9.59026697e-03 -1.48980052e-01 -1.30614315e-02  1.92070356e-01\n",
      "   9.69325293e-02  2.05336199e-02  1.16926814e-01 -7.62854742e-02\n",
      "  -1.50663127e-01  2.14221650e-01 -1.58290424e-02 -3.91981665e-02\n",
      "   3.27219184e-02 -3.91926240e-02  5.29888217e-02  1.88506431e-02\n",
      "  -5.89302808e-02  7.36837487e-02 -7.54230480e-02  8.92232093e-02\n",
      "   1.47885893e-01 -1.13032360e-01 -5.13552758e-02 -1.53018917e-01\n",
      "  -3.48127786e-02  1.34395262e-01 -3.98347880e-02 -1.67804003e-01\n",
      "  -1.11446306e-01 -2.13644297e-02  1.94120970e-02 -1.25605589e-02\n",
      "   1.72498665e-01  1.11250400e-01  7.28536924e-02 -1.54778297e-02\n",
      "   2.67574972e-01  1.69666943e-02  6.84817750e-02 -1.88378081e-01\n",
      "  -2.12769411e-01  5.32340769e-02 -1.03986831e-01  6.59412791e-03\n",
      "   1.54907410e-01  9.66891842e-02  2.92605202e-02 -3.47510449e-02\n",
      "  -1.82777360e-01 -1.45402780e-02  4.50596605e-03 -1.00440611e-01\n",
      "   1.48518927e-01  2.39272165e-02 -9.52458936e-02  4.07148945e-02\n",
      "  -2.19617321e-02 -7.71921921e-02  6.74680325e-02 -1.99676841e-02\n",
      "  -3.07087862e-02  3.21245678e-02 -2.03990760e-01 -7.66261915e-02\n",
      "   6.83375528e-02 -7.04300450e-02  4.44077261e-02  1.60180194e-01\n",
      "  -1.09597808e-01  1.33698400e-01  2.71195000e-01 -4.93607918e-02\n",
      "  -2.11949415e-01  3.60557081e-02  9.64658790e-02  1.40587026e-01\n",
      "   3.55713330e-02 -9.10186040e-02 -1.20939333e-01  5.31818474e-02\n",
      "   1.62898811e-01 -1.00939051e-01  5.35621631e-02  2.42021744e-02\n",
      "   6.77472783e-02 -6.34393067e-02 -9.80618058e-03  1.08318331e-01\n",
      "  -2.41858394e-02 -9.66236336e-02  2.90853747e-02 -1.05511643e-01\n",
      "  -9.25115991e-02  2.79342046e-02 -6.65598114e-02  5.67996838e-02]\n",
      " [-1.11146708e-01 -1.86781853e-02  3.17516090e-02  5.00427674e-02\n",
      "  -5.94232199e-02 -1.52256770e-01 -9.17174287e-02  5.00853820e-02\n",
      "  -3.53685011e-02 -1.66969009e-01  5.31710721e-03 -5.86183298e-02\n",
      "  -1.95142131e-02 -1.00182946e-02  1.61662080e-01 -7.20547711e-02\n",
      "   1.22949217e-02 -5.92569941e-02 -1.31495540e-01  3.51731773e-03\n",
      "  -1.62221117e-01  4.78983675e-02  8.85648425e-02  2.23296041e-02\n",
      "  -8.86422010e-03  5.84574238e-02 -3.90359326e-02  1.18080788e-02\n",
      "  -1.69853823e-01  2.34128655e-01 -8.79236662e-02 -1.88711960e-02\n",
      "   7.50400882e-03 -1.96064654e-03  1.09495853e-01 -7.70515641e-02\n",
      "   1.38896277e-01 -5.41136273e-02  1.46131283e-01 -4.59134231e-02\n",
      "   4.41610134e-02  5.33744035e-02 -1.33747633e-01  1.73188714e-01\n",
      "  -1.58437982e-01 -4.48234077e-02  1.11397708e-01  9.76377907e-02\n",
      "  -1.04351086e-01  2.44400866e-01  1.97766942e-02 -1.46582951e-01\n",
      "   1.26302108e-01  3.82712494e-02  7.55056170e-02 -1.88959849e-01\n",
      "   3.98425850e-02  1.41014695e-01 -4.27332011e-02  9.55515278e-02\n",
      "   2.89040690e-02  2.44094769e-01  8.71730151e-02 -9.30841520e-02\n",
      "  -4.62375225e-02 -5.46680469e-02  1.11261237e-01  1.12619575e-02\n",
      "  -8.78629117e-02  2.03153972e-01 -1.63798274e-02  7.98546807e-02\n",
      "   7.24772567e-02 -2.52531808e-01  1.24557482e-02 -3.28768189e-02\n",
      "  -1.69162739e-01  1.24260269e-01 -3.51440896e-02 -2.34344498e-02\n",
      "  -1.24909047e-01 -6.97902302e-02 -1.70339527e-01  1.71682103e-01\n",
      "   1.69441564e-01 -4.09163709e-02 -6.65938510e-02  1.16703679e-01\n",
      "  -1.83261031e-01  1.23950173e-01 -3.53810115e-02  1.82678693e-02\n",
      "   8.84268794e-02  8.63511155e-02 -2.63242448e-01  2.06022965e-02\n",
      "   6.50146147e-02  5.85904801e-02 -6.93297732e-02 -1.04039112e-01\n",
      "   7.82171548e-02  3.69939042e-02  9.17263622e-02  2.26934580e-02\n",
      "   9.52607048e-02  1.18699765e-01 -1.02254424e-01  1.30393507e-01\n",
      "  -1.95094253e-01 -3.25717108e-02 -8.64470306e-02 -6.34140551e-03\n",
      "   1.84370067e-01 -8.14134443e-02  4.88841442e-02 -1.95610190e-01\n",
      "  -3.71436458e-02 -4.67642869e-03 -2.26423512e-02 -1.03112650e-01\n",
      "   3.59850549e-02  3.67875514e-02  1.30994887e-01 -1.42483581e-01\n",
      "   2.18933124e-01  8.19254866e-02  4.11468431e-02 -1.29639746e-01]\n",
      " [-1.81124058e-02  8.78376353e-02  1.10009314e-02  3.25241606e-01\n",
      "  -2.31383838e-03  1.79720131e-01  8.04039082e-02  1.71299907e-01\n",
      "   3.68638324e-02 -2.02062725e-02 -7.68740502e-02  7.48149994e-03\n",
      "  -9.54406628e-02 -7.06464105e-02  2.87464707e-02 -1.68143766e-01\n",
      "   1.10723164e-01  9.68869279e-02  1.24520484e-01 -1.58794248e-01\n",
      "  -1.04508424e-01 -1.26176616e-01 -2.85424608e-02 -4.29938241e-02\n",
      "  -2.27223138e-02  9.72106974e-02 -1.77443958e-01 -2.24617893e-01\n",
      "   3.26351028e-02 -1.07082558e-01  5.12482905e-02  1.35390813e-01\n",
      "   4.97282370e-02 -4.73373709e-02 -1.15108013e-01 -1.78192064e-01\n",
      "  -1.02268348e-01  1.15382464e-02 -1.28414333e-02 -1.70016239e-01\n",
      "  -1.03105176e-02  8.52366459e-02 -1.05735233e-02 -1.67662616e-02\n",
      "  -1.57182836e-01 -3.43093846e-02  3.07970172e-05  3.69899993e-02\n",
      "   2.60079971e-01 -1.57284307e-01  4.76778771e-02  1.23817843e-01\n",
      "   1.95120223e-02  1.04085016e-02  9.04213710e-03  1.76157854e-01\n",
      "  -1.14135933e-01  6.84617986e-02 -2.55453259e-02  1.82076337e-01\n",
      "   6.82930922e-03 -1.16626877e-01 -7.08520229e-02 -2.44443867e-02\n",
      "   1.13423697e-01  1.60889146e-02 -1.63528921e-01 -1.33427603e-01\n",
      "   1.65679079e-01  4.51169686e-02 -8.39686009e-02  1.08965908e-01\n",
      "   6.73682834e-02 -1.74001087e-01 -1.15656506e-01  1.09750424e-01\n",
      "  -7.63060758e-02  1.69608524e-01  1.58674496e-01 -2.28997455e-02\n",
      "  -1.24210198e-01 -2.00291759e-01 -1.26992184e-01 -4.83571695e-02\n",
      "  -4.55696021e-03 -1.63528501e-01  1.03600917e-01 -5.92631877e-02\n",
      "   2.51344405e-02 -5.85852787e-02 -2.38460844e-01 -9.95267929e-02\n",
      "  -8.08586805e-03 -1.40967927e-01 -6.72346972e-02  9.65300668e-02\n",
      "  -7.41627513e-02  5.27703679e-02 -1.62438350e-01 -5.52830741e-02\n",
      "  -2.50140131e-02 -6.97218558e-02  4.85790958e-02 -7.06966110e-02\n",
      "   4.67381952e-02 -7.75735305e-02 -6.18510204e-02  6.01657164e-02\n",
      "  -1.10426309e-02 -1.07323493e-01 -2.87286043e-02 -1.13593064e-02\n",
      "  -3.96371582e-02  2.06707488e-01 -3.65436507e-02  1.70214794e-01\n",
      "   1.78132451e-02  1.19131234e-01  9.14734049e-02  3.73864405e-02\n",
      "  -8.52317100e-02  1.42963571e-01  1.24403301e-02  3.83370290e-03\n",
      "   8.89496316e-02  6.73880558e-02 -1.20776587e-01  9.24631017e-02]\n",
      " [ 1.06009274e-01 -6.70678667e-02  8.69228479e-02 -1.67069020e-01\n",
      "   2.96425430e-02  1.14749913e-01 -7.27775354e-02 -8.89382709e-02\n",
      "   7.25253379e-02 -1.24954978e-01  5.75148710e-02 -1.80064456e-02\n",
      "   7.61267950e-02 -1.21748375e-01 -1.52601537e-01 -4.70978159e-02\n",
      "  -8.14044477e-02 -9.34009718e-04 -1.66722505e-02  4.56562152e-02\n",
      "   1.88306980e-02  3.31873458e-02  2.56351124e-02  8.60811900e-02\n",
      "  -2.25569206e-02  1.55145411e-01 -4.82641724e-02  1.23655124e-01\n",
      "   1.02051004e-01 -7.91537512e-02 -3.07616828e-02  8.00845680e-02\n",
      "   3.85122013e-02 -1.57025804e-01 -7.07179301e-02  9.64434860e-02\n",
      "  -3.79070383e-02  7.82153069e-02 -5.74160308e-03  5.32850358e-02\n",
      "   4.75101794e-02 -8.29794563e-02 -3.41290080e-02 -1.89450274e-01\n",
      "   4.80924352e-03  2.95650112e-02  5.77255191e-02  8.47990957e-02\n",
      "   1.42370825e-01 -2.19369092e-02  1.00219489e-01 -4.93832698e-02\n",
      "  -1.58760625e-01 -2.70168393e-01 -1.26891694e-01  1.35298267e-01\n",
      "  -4.01975238e-03 -1.96034415e-03  7.69882381e-03 -7.17786897e-02\n",
      "   2.86310776e-01 -8.55689675e-02  5.64253358e-02  6.42411095e-02\n",
      "  -1.46482154e-01 -1.01170530e-02  1.77654408e-02 -1.47749228e-02\n",
      "  -1.43736892e-01  3.99481044e-02 -8.80902351e-02  3.50479731e-02\n",
      "   2.62515399e-02 -6.87861576e-02 -1.25245245e-02 -1.32614589e-01\n",
      "  -2.77809062e-02  8.43786955e-02  3.59004867e-02  7.62406882e-02\n",
      "  -2.31459974e-02  7.37651817e-04  5.58526865e-02 -4.00171713e-03\n",
      "   8.06432092e-02 -1.41068644e-01  1.41893030e-01  1.70294537e-01\n",
      "  -8.57732140e-02  2.13071951e-01  1.59937230e-01 -6.48927677e-02\n",
      "   3.63100311e-02  6.93857357e-02 -2.49456246e-01 -5.45785777e-02\n",
      "  -7.36677596e-02  1.47788080e-01 -1.04870372e-01  1.16115026e-01\n",
      "   1.52233217e-01  1.74533545e-03  2.10919900e-03 -7.44336945e-02\n",
      "   2.87642558e-02 -5.63798396e-02 -7.31746624e-02 -1.35075464e-01\n",
      "  -2.46536134e-03  1.36675985e-02  2.73336908e-02 -1.72689524e-01\n",
      "  -1.38904971e-01  5.95338313e-02  5.99803126e-02 -1.11844279e-02\n",
      "   1.99474707e-01  2.04630141e-01 -1.54125341e-02  6.09668060e-02\n",
      "  -1.63675346e-01 -6.54499386e-03  2.15772338e-03  9.46603760e-02\n",
      "   1.37411300e-01  1.06501186e-01  2.49982634e-02  1.29165623e-01]\n",
      " [-1.18924359e-01 -7.17256379e-02 -3.01526028e-02 -9.23565008e-03\n",
      "   3.40962050e-02 -2.17789623e-01  1.66582637e-02  1.06061097e-02\n",
      "   3.87297407e-02  2.31587224e-02  3.50239748e-02  3.54528989e-02\n",
      "   2.06796452e-02 -5.24782289e-02  9.70602108e-02  4.21232713e-02\n",
      "  -4.61468046e-02 -1.67589518e-03 -9.56039742e-02 -1.84938431e-01\n",
      "   1.51454275e-01 -1.70067750e-01 -9.04055746e-02 -2.87760257e-02\n",
      "   1.15703353e-01  1.17744206e-01 -2.03152762e-01  2.37427210e-02\n",
      "   1.65481692e-01 -2.01713197e-02  7.74226397e-02 -1.20180193e-01\n",
      "   8.16747386e-02 -5.54941349e-02 -5.97873225e-02  3.39631307e-02\n",
      "  -4.80817335e-02  5.89322476e-03 -1.46638503e-01  2.86443397e-02\n",
      "   1.35916531e-02  7.79034267e-02  1.89814846e-01  2.89481155e-02\n",
      "  -1.41589525e-01  1.62617393e-02 -1.04081292e-01  4.29260548e-02\n",
      "  -5.66244018e-02 -1.37127880e-02 -8.10866090e-02  1.38222703e-01\n",
      "  -6.87122506e-02 -2.36570432e-02  4.69744516e-02 -1.91048017e-02\n",
      "   5.86803616e-02 -6.58578980e-02  9.73502469e-02  5.18662531e-02\n",
      "   7.66404027e-02  9.77468378e-02 -1.96648654e-01 -1.32860058e-01\n",
      "   1.29001128e-01  1.20337625e-01  9.58046314e-02  6.50616762e-02\n",
      "   1.31224800e-01  6.50837669e-02  3.53391231e-02 -1.11387674e-01\n",
      "  -1.26418381e-01  1.14062121e-01  1.11238923e-01  7.76822597e-02\n",
      "  -1.39619993e-02  2.91341307e-03  7.40234199e-04 -7.63318016e-02\n",
      "  -1.25390670e-01 -8.26017343e-03 -2.79010700e-02 -7.30851117e-02\n",
      "   8.18894998e-02 -6.63477621e-02  6.69990281e-03  1.09574386e-02\n",
      "   3.85304953e-02  1.75513719e-01  1.70408380e-02 -4.57922807e-03\n",
      "   1.19233520e-01 -3.86692732e-02  1.19415297e-01  1.11168047e-01\n",
      "   8.87814716e-02  3.14502759e-02 -2.63960146e-02 -8.72051271e-02\n",
      "   1.76204027e-01  8.49841021e-02 -8.66106578e-02 -1.28678430e-01\n",
      "   1.90401823e-02  3.87585928e-02  3.81236415e-02 -1.36038957e-01\n",
      "   2.36219657e-02  1.31075540e-01 -1.91245154e-01  8.19717963e-02\n",
      "   8.37233519e-02  9.89172487e-02  6.24790800e-02  2.45128893e-03\n",
      "   4.75573217e-02 -1.81343892e-02 -7.43084767e-02 -1.10120064e-01\n",
      "   1.44893012e-02  9.48958922e-02  5.48657357e-02 -5.18317465e-02\n",
      "  -6.80924042e-02  1.05742822e-01  1.17123727e-01  1.92700013e-01]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "create_bias_and_weights(6,128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do artificial & biological neural nets compare?\n",
    "\n",
    "Artificial Neural Networks are inspired by the hierarchial structure of brains neural network\n",
    "\n",
    "![alt text](https://appliedgo.net/media/perceptron/neuron.png \"Logo Title Text 1\")\n",
    "\n",
    "The brain has \n",
    "-100 billion neurons \n",
    "-- Each neuron has\n",
    "   - A cell body w/ connections\n",
    "   - numerous dendrites \n",
    "   - A single axon \n",
    "- Parallel chaining (each neurons connected to 10,000+ others)\n",
    "- Great at connecting different concepts\n",
    "\n",
    "Computers have\n",
    "- Not neurons, but transistors made in silicon!\n",
    "- Serially chained (each connected to 2-3 others (logic gates))\n",
    "- Great at storage and recall\n",
    "\n",
    "Some key differences\n",
    "- All sensory or motor systems in the brain are recurrent\n",
    "- Sensory systems tend to have lots of lateral inhibition (neurons inhibiting other neurons in the same layer)\n",
    "- There is no such thing as a fully connected layer in the brain, connectivity is usually sparse (though not random).\n",
    "- brains are born pre-wired to learn without supervision.\n",
    "- The Brain is low power. Alpha GO consumed the power of 1202 CPUs and 176 GPUs, not to train, but just to run. Brainâ€™s power consumption is ~20W.\n",
    "\n",
    "![alt text](https://images.gr-assets.com/books/1348246481l/5080355.jpg\n",
    " \"Logo Title Text 1\")\n",
    "\n",
    "\"the brain is not a blank slate of neuronal layers \n",
    "waiting to be pieced together and wired-up; \n",
    "we are born with brains already structured \n",
    "for unsupervised learning in a dozen cognitive \n",
    "domains, some of which already work pretty well \n",
    "without any learning at all.\" - Steven Pinker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =  [[3.1,2.1,9.8,1.0],\n",
    "          [5.1,6.1,4.8,7.0],\n",
    "          [6.1,4.1,5.8,6.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense():\n",
    "    def __init__(self,inputs,neurons):\n",
    "        self.weights = 0.10*np.random.randn(inputs,neurons)\n",
    "        self.biases = np.zeros((1,neurons))\n",
    "    def forward(self,inputs):\n",
    "        self.output = np.dot(inputs,self.weights) + self.biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = Dense(4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Dense at 0x2904ae54608>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.10152064  0.1017865   0.30105313 -1.49946945  0.84348851]\n",
      " [-1.10396292 -0.6766822   0.67612415 -0.29111452  0.16715133]\n",
      " [-1.25728793 -0.38877619  0.52298024 -0.44106244  0.23215512]]\n"
     ]
    }
   ],
   "source": [
    "print(layer1.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer2 = Dense(5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer2.forward(layer1.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.27329422 -0.19157428]\n",
      " [-0.24756747 -0.1221705 ]\n",
      " [-0.25344906 -0.09829976]]\n"
     ]
    }
   ],
   "source": [
    "print(layer2.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu():\n",
    "    def forward(self,inputs):\n",
    "        self.output = np.maximum(0,inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = Relu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation.forward(layer1.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.1017865  0.30105313 0.         0.84348851]\n",
      " [0.         0.         0.67612415 0.         0.16715133]\n",
      " [0.         0.         0.52298024 0.         0.23215512]]\n"
     ]
    }
   ],
   "source": [
    "print(activation.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Research Directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Bayesian Deep Learning (smarter backprop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Spike-Timing-Dependent Plasticity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deep Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evolutionary Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Better Hardware"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/karpathy.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
